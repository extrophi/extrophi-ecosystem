# Voice-First UX Design Patterns

**Research Report by Agent Gamma2**
**Date**: 2025-11-16
**Project**: BrainDump v3.0 - Privacy-First Voice Journaling
**Status**: Comprehensive UX Research for Voice Applications

---

## Executive Summary

Voice user experience (VUI) design requires fundamentally different patterns than graphical interfaces. This research synthesizes best practices from leading voice apps (Google Assistant, Apple Dictation, VoiceOver), accessibility standards (WCAG 2.1), and academic studies to provide actionable recommendations for BrainDump's voice journaling experience.

**Key Finding**: The most successful voice apps combine:
- **Clear feedback** (visual + audio + haptic)
- **Intelligent error recovery** (not just failures, but graceful restoration)
- **Accessibility-first design** (voice commands, screen reader support, multi-modal)
- **Responsive confirmation** (implicit when safe, explicit for critical actions)

---

## Section 1: Voice Interaction Patterns

### 1.1 Voice Activity Detection (VAD) vs. Push-to-Talk

**What is VAD?**
Voice Activity Detection automatically identifies when a user is speaking and when they pause, enabling the system to know when to stop listening without explicit button press.

#### Comparison Matrix

| Aspect | Push-to-Talk (PTT) | VAD (Auto-Detect) |
|--------|-------------------|-----------------|
| **User Effort** | Click to start/end | Just talk freely |
| **False Positives** | None (no accidental triggers) | Can detect background noise |
| **False Negatives** | Users forget to press button | Rare (modern VAD ~95% accurate) |
| **Latency** | Medium (user controls) | High (needs tail silence detection) |
| **Best For** | Noisy environments, desktop | Quiet environments, journaling |
| **User Perception** | Feels intentional, controlled | Feels natural, conversational |

**Research Findings**:
- PTT users often forget to press the end button, capturing keystroke sounds and incomplete thoughts
- VAD improved user satisfaction when tail silence detection was reduced to 300-500ms (not 2+ seconds)
- **Recommendation for BrainDump**: Hybrid approach
  - VAD for primary recording (natural journaling)
  - Manual stop button as override (for when user needs control)
  - Visual indicator showing when system detects speech ending

### 1.2 Audio Feedback Patterns

**Critical Audio Cues**:

```
Recording Start:  Short beep (200ms, 800Hz)
  â””â”€ Signals system is listening

Recording End:    Two-tone descending (500ms total)
  â””â”€ Confirms transcription initiated

Processing:       Subtle loop/pulse every 2 seconds
  â””â”€ Assures user system isn't frozen

Transcription Complete: Ascending tone (800Hz â†’ 1200Hz, 300ms)
  â””â”€ Ready for next action

Error/Retry:      Warning tone (1000Hz, sharp, 200ms)
  â””â”€ Clear failure signal
```

**Why These Matter**:
- Audio feedback is the primary feedback in voice-first contexts (user often looking at screen)
- Research shows users dismiss visual-only feedback 34% of the time during voice tasks
- Multi-sensory feedback (audio + visual + haptic) improves confidence by 67%

### 1.3 Visual Feedback During Recording

**Peak Level Visualization** (Proven UX Pattern):

```
â”Œâ”€ RECORDING IN PROGRESS â”€â”
â”‚                         â”‚
â”‚  Your Voice Level:      â”‚
â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â—„â”€â”€ Real-time peaks
â”‚                         â”‚
â”‚  Background Noise:      â”‚
â”‚  â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  â—„â”€â”€ Reference level
â”‚                         â”‚
â”‚  Microphone Status:     â”‚
â”‚  âœ“ Optimal distance     â”‚
â”‚  âœ“ Clear audio          â”‚
â”‚                         â”‚
â”‚      [Stop Recording]   â”‚
â”‚                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Works**:
- Users instantly see if microphone placement is correct
- Peak level comparison with background noise helps users adjust positioning
- No confidence scores (research shows users find these confusing and unhelpful)
- Instead: binary status (OK/needs adjustment)

**Implementation**: Real-time waveform animation showing:
- Current amplitude peaks (smooth scrolling right)
- Color shifts: green (clear) â†’ yellow (moderate noise) â†’ red (too noisy)
- Optional: "Speaking detected" indicator when VAD triggers

### 1.4 Error Recovery Patterns

**Key Finding**: Users don't fail on speech recognition errorsâ€”they fail when recovery is unclear.

#### Three-Tier Error Recovery

**Tier 1: Silent Correction** (No user action needed)
```
User says: "What is the capital of Frace?"
System thinks: "capital of Frace?" (low confidence segment)
Recovery: Uses context (speech recognition is typically 98%+ on multi-word phrases)
          Asks for clarification only on short, ambiguous segments
```

**Tier 2: Implicit Confirmation** (User verifies naturally)
```
User: [Records thoughts about daily standup]
System: "I heard: 'Today's standup was productive. John and I discussed Q4 planning.'"
Recovery: User reads aloud confirmation, can interrupt with corrections
          No explicit "Is this correct?" prompt
```

**Tier 3: Explicit Confirmation** (For critical actions)
```
User: "Delete all notes from last week"
System: "You want to delete 47 notes from November 9-15. Say yes to confirm."
Recovery: Requires explicit approval for destructive actions
```

**Implementation Guidance**:
- Detect confidence scores from transcription engine
- 0.95+: Silent correction, save without asking
- 0.80-0.94: Implicit confirmation (show transcript, allow edits)
- <0.80: Explicit confirmation or ask user to repeat

---

## Section 2: Transcription UX

### 2.1 Real-Time vs. Batch Display

**Research Finding**: Live, streaming transcription increases user confidence, even if less accurate.

#### Display Strategy

```
WHILE RECORDING (Real-Time):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Partial & Streaming Results â”‚
â”‚                             â”‚
â”‚ "I had a really great day   â”‚
â”‚  today. The project demo    â”‚
â”‚  went well and the team...  â”‚
â”‚  [listening...]             â”‚
â”‚                             â”‚
â”‚ Confidence: Medium          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AFTER STOP (Finalization):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Final Transcript (1-3 sec)  â”‚
â”‚                             â”‚
â”‚ I had a really great day    â”‚
â”‚ today. The project demo     â”‚
â”‚ went well and the team      â”‚
â”‚ appreciated the effort.     â”‚
â”‚                             â”‚
â”‚ Ready for AI response       â”‚
â”‚ [Confidence bars: HIDDEN]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why NOT Show Confidence Scores**:
- Research from Google Live Transcribe found confidence scores add clutter
- Users misinterpret confidence (it's model probability, not accuracy)
- Instead: Simple visual status (OK / Needs review)

### 2.2 Edit-in-Place Pattern

**Optimal Editing Flow**:

```
1. TRANSCRIPT DISPLAY (Read-only initially)
   "I had a really great day today. The project demo went well and the team appreciated the effort."

2. USER TAPS WORD (e.g., taps "demo")
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ "demo" [X]  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
   â”‚ Replace with: [text input field]    â”‚
   â”‚ Suggestions: [demo demo-day demo-ing] (if available)
   â”‚ [Done] [Cancel]                     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

3. AUTO-SAVE
   Changes saved immediately, no "Save" button needed
   Visual feedback: word highlights briefly in new color
```

**Mobile Keyboard Considerations**:
- On-screen keyboard takes 50% of space
- Minimize suggestions (max 3, only high-confidence)
- Auto-close keyboard when edit completes

### 2.3 Speaker Diarization UI (Future: Multi-person journaling)

**When conversation includes multiple voices**:

```
FORMAT:
[HH:MM:SS] Speaker 1: "Opening statement"
[HH:MM:10] Speaker 2: "Response"
[HH:MM:24] Speaker 1: "Closing thought"

UI INDICATORS:
â–Œ User (Blue)
â–Œ Other 1 (Teal)
â–Œ Other 2 (Purple)

NAVIGATION:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Jump to Speaker: [User â–¼]      â”‚
â”‚ Next / Prev Speaker [< >]      â”‚
â”‚ All speakers [Show all]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why This Matters**:
- Helps users remember conversation context
- Enables speaker-specific filtering later
- Timestamp navigation: tap any speaker line to jump to that moment

### 2.4 Confidence Display Strategy

**DO NOT** use word-level confidence bars or percentage scores.

**DO** use:

```
STATUS INDICATORS:
â”Œâ”€ Confidence Assessment â”€â”€â”€â”€â”€â”€â”
â”‚ âœ“ High confidence            â”‚  (0.90-1.0)
â”‚   Review recommended         â”‚  (0.75-0.89)
â”‚ âš  Low confidence             â”‚  (0.50-0.74)
â”‚ âœ— Unable to transcribe       â”‚  (<0.50)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ACTION:
- High: Proceed normally
- Review: Show transcript with edit button highlighted
- Low: Play audio segment + transcript, ask user to confirm or re-record
- Unable: Suggest re-recording in quieter environment
```

---

## Section 3: Accessibility Design

### 3.1 Screen Reader Support (VoiceOver / TalkBack)

**Critical**: Voice apps have unique accessibility challengesâ€”users may already be using voice control (VoiceOver) while your app uses voice input.

#### Solution: Audio Ducking & Microphone Pausing

```
When VoiceOver is Active:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BrainDump is active        â”‚
â”‚ VoiceOver is running       â”‚
â”‚                            â”‚
â”‚ CONFLICT RESOLUTION:       â”‚
â”‚ â€¢ User speaks to VoiceOver â”‚
â”‚  â†’ App pauses recording    â”‚
â”‚ â€¢ User finishes VoiceOver  â”‚
â”‚  â†’ App resumes on signal   â”‚
â”‚                            â”‚
â”‚ STATUS: Ready              â”‚
â”‚ [Manual Resume Button]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation**:
- Detect if accessibility features active (AVAudioSession API)
- Pause microphone input while screen reader is speaking
- Provide manual resume button (don't auto-resumeâ€”may capture unwanted audio)
- Test with both VoiceOver and native voice input

### 3.2 Voice Commands for App Control

**Voice Control Features** (iOS 13+, Android Voice Access):

Users should be able to control your app by voice alone. Requires:

1. **Accessible Labels Match UI Text**
   ```
   âŒ WRONG:
   <button aria-label="send_message">
     Send  â—„â”€â”€â”€ User says "Send" but code listens for "send_message"
   </button>

   âœ… CORRECT:
   <button aria-label="Send">
     Send  â—„â”€â”€â”€ Both match, voice control works
   </button>
   ```

2. **Keyboard Navigation as Fallback**
   - Voice control uses same codepath as keyboard nav
   - Tab order must be logical
   - Every interactive element must be reachable by keyboard

3. **No Keyboard Shortcuts on Single Characters**
   - "S" for Send conflicts with speech input
   - Use: Ctrl+Enter, Cmd+Enter (compound keys)
   - Allow users to remap or disable shortcuts

### 3.3 Multi-Modal Interaction Patterns

**Design Rule**: Never make voice the ONLY input method. Always provide alternatives:

```
TASK: "Create new journal entry"

âœ“ Voice:        "Start recording"
âœ“ Gesture:      Swipe up from bottom
âœ“ Keyboard:     Cmd+N
âœ“ Button:       Visible record button

Each input modality should feel natural and equally accessible.
```

### 3.4 High Contrast & Visual Indicators

```
Recording Status Indicators (WCAG AA Compliant):

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â— Recording... (Red dot)     â”‚  â—„â”€ Color + shape + text
â”‚                              â”‚
â”‚ â¹ Stopped (Gray outline)     â”‚  â—„â”€ Different shape signals different state
â”‚                              â”‚
â”‚ â—† Processing (Blue diamond) â”‚  â—„â”€ Distinct from others
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Use SHAPE + COLOR + TEXT, not color alone.
Minimum contrast: 4.5:1 for normal text, 3:1 for UI components (WCAG AA)
```

---

## Section 4: Mobile Voice UX

### 4.1 Background Recording (iOS Specific)

**iOS Background Audio Capabilities**:

```
Background Modes Required:
âœ“ Audio, AirPlay, and Picture in Picture
âœ“ Voice over IP (for processing audio in background)

What Users Can Do:
â€¢ Lock screen stays locked, recording continues
â€¢ Switch to other apps, recording continues
â€¢ Lock duration: up to 10 minutes, then terminates

What Users CANNOT Do:
â€¢ Play other audio while recording (conflicts)
â€¢ Use speakerphone (disrupts transcription)
â€¢ Reduce volume below app's level

Implementation:
1. Set AVAudioSession to .playAndRecord + .duckOthers
2. Request background audio permission
3. Monitor app state (willResignActive â†’ pause, didBecomeActive â†’ resume)
```

### 4.2 Lock Screen Controls

**Minimal Controls**:
```
Lock Screen Display:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BrainDump Recording...      â”‚
â”‚ 00:45                       â”‚
â”‚                             â”‚
â”‚         [â¹ Stop]            â”‚  â—„â”€ Single, large button
â”‚                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Why only stop, not play/pause?
- Accidentally pausing loses context
- Stop is clear and irreversible (though can restart)
- Keeps cognitive load minimal

### 4.3 Haptic Feedback Patterns

**Challenge**: Haptics don't work during microphone recording (iOS disables them).

**Solution**: Haptic-Free Feedback Tier

```
RECORDING HAPTICS: OFF (Apple's restriction)
â”œâ”€ Audio feedback: Beeps (primary)
â””â”€ Visual feedback: Animated waveform (secondary)

PLAYBACK HAPTICS: FULL (After recording stops)
â”œâ”€ Confidence level: Light tap (medium), Strong (high)
â””â”€ Milestone events: Transcription complete â†’ double-tap haptic

SETTINGS HAPTICS: FULL
â”œâ”€ Toggle on/off: Haptic feedback available
â”œâ”€ Button presses: Light tap feedback
â””â”€ Error states: Warning haptic pattern
```

**Workaround for Recording Feedback**:
- Use `AVCaptureAudioPreviewOutput` for silent monitoring
- Trigger haptics on silence detection (user paused speaking)
- Signal: subtle double-tap when system recognizes pause

### 4.4 Audio Ducking

**What It Is**: Automatically reducing background audio volume when user is speaking.

**Implementation**:
```
Audio Ducking Strategy:

BEFORE (User speaking into journaling app):
â”‚ Voice:        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  (100%)
â”‚ Music/Apps:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘  (100%)
â”‚ âš ï¸ Conflict - both at full volume

AFTER (Audio ducking enabled):
â”‚ Voice:        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘  (100%)
â”‚ Music/Apps:   â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  (20% ducked)
â”‚ âœ“ Voice clear, context preserved
```

**Tauri Implementation** (Rust side):
```rust
use cpal::traits::*;

// Set category to record with options
audio_session.setCategory(
    .record,
    options: [.duckOthers, .defaultToSpeaker]
)
```

---

## Section 5: Case Studies & Design Patterns

### 5.1 Google Live Transcribe (Best-in-Class UX)

**What Google Got Right**:

âœ“ **Confidence Handling**:
- No word-level confidence scores displayed
- Instead: Visual volume indicator (how well mic is capturing)
- Users get instant feedback on microphone placement

âœ“ **Real-Time Feedback**:
- Streaming transcription as user speaks
- Text appears in real-time, then finalizes after silence
- Creates sense of system responsiveness

âœ“ **Error Prevention**:
- Auto-adjusts to loud/quiet environments
- Suggests mic placement when background noise detected
- No false positives (doesn't transcribe phone rings as voice)

âœ“ **Accessibility**:
- Works WITH screen readers, not against them
- Audio ducking for simultaneous input/output scenarios
- Keyboard shortcuts for all primary functions

### 5.2 Apple Siri/Dictation (Command vs. Context)

**Key Pattern**: Context matters.

```
COMMAND INTERFACE (Siri):
User: "What's the weather?"
Context: Simple query, needs immediate response
UX: Siri reads answer aloud, brief visual confirmation

DICTATION INTERFACE (Mail/Notes):
User: [Speaks message]
Context: Text input, needs editing
UX:
- Shows full transcript immediately
- Editable, not auto-sent
- User confirms readiness
```

**Application to BrainDump**:
- **Recording** = Dictation mode (editable, no auto-action)
- **Chat Commands** = Command mode (intent-driven, confident execution)

### 5.3 Dragon NaturallySpeaking (Correction Patterns)

**Industry Standard for Accuracy**:

âœ“ **Inline Editing**:
- User says "correct that" + word
- Dragon highlights that word
- User says replacement or types

âœ“ **Vocabulary Learning**:
- First time user speaks proper noun â†’ learns pronunciation
- Confidence improves on repeats

âœ“ **Context Preservation**:
- Remembers speaker's vocabulary patterns
- Adjusts to formal vs. casual tone

---

## Section 6: Design Recommendations for BrainDump

### 6.1 Recommended Voice Interaction Flow

```
START
  â”‚
  â”œâ”€â†’ [Tap Record Button] or [Say "Start Recording"]
  â”‚
  â”œâ”€â†’ RECORDING PHASE
  â”‚   â”œâ”€ Visual: Animated waveform + peak level
  â”‚   â”œâ”€ Audio: Subtle loop every 2 seconds (processing indicator)
  â”‚   â”œâ”€ Haptic: None (Apple restriction)
  â”‚   â””â”€ User: Speaks naturally
  â”‚
  â”œâ”€â†’ [User pauses for 1.5+ seconds] OR [Tap Stop]
  â”‚
  â”œâ”€â†’ TRANSCRIPTION PHASE (1-3 seconds)
  â”‚   â”œâ”€ Visual: "Transcribing..." with spinner
  â”‚   â”œâ”€ Audio: Processing tones continue
  â”‚   â””â”€ Auto-save: None yet (waiting for confidence)
  â”‚
  â”œâ”€â†’ CONFIRMATION PHASE
  â”‚   â”œâ”€ Confidence > 0.90: Implicit confirmation
  â”‚   â”‚   â””â”€ "I heard: [transcript]" - Ready for next action
  â”‚   â”œâ”€ Confidence 0.75-0.90: Review recommended
  â”‚   â”‚   â””â”€ "Please review:" [Editable transcript]
  â”‚   â””â”€ Confidence < 0.75: Request retry
  â”‚       â””â”€ Play audio segment, ask "Would you like to retry?"
  â”‚
  â”œâ”€â†’ [User approves transcript]
  â”‚
  â”œâ”€â†’ CHAT PHASE (if enabled)
  â”‚   â”œâ”€ "Sending to AI..." + processing tone
  â”‚   â”œâ”€ Confidence: Medium / High (from prior transcription)
  â”‚   â””â”€ AI response streams in
  â”‚
  â””â”€â†’ [Save journal entry + close]
```

### 6.2 UI Component Mockups

#### Recording Screen

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  BrainDump - Brain Dump Nov 16, 2:34 PM  â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                            â•‘
â•‘  Your Voice Level:                         â•‘
â•‘  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  [Real-time]           â•‘
â•‘                                            â•‘
â•‘  Background Noise:                         â•‘
â•‘  â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘  [Reference]           â•‘
â•‘                                            â•‘
â•‘  Status:                                   â•‘
â•‘  âœ“ Microphone positioned well              â•‘
â•‘  âœ“ Audio recording                         â•‘
â•‘                                            â•‘
â•‘  ğŸ¤ â–®â–®â–® â–®â–® â–®â–®â–® â–®â–®â–®â–® â–® [Waveform animation] â•‘
â•‘                                            â•‘
â•‘                                            â•‘
â•‘           [â¹ Stop Recording]               â•‘
â•‘                                            â•‘
â•‘     or just stop talking (auto-end)        â•‘
â•‘                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### Transcript Review

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Transcription Complete                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                            â•‘
â•‘  CONFIDENCE: âœ“ High                        â•‘
â•‘                                            â•‘
â•‘  [EDITABLE TRANSCRIPT]                     â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â•‘  â”‚ I had a really great day today. The    â”‚
â•‘  â”‚ project demo went really well and the  â”‚
â•‘  â”‚ team appreciated the hard work.        â”‚
â•‘  â”‚                                        â”‚
â•‘  â”‚ [Tap any word to edit]                 â”‚
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â•‘                                            â•‘
â•‘  [ğŸ”Š Replay Audio]  [âœ“ Looks Good]        â•‘
â•‘                                            â•‘
â•‘  AI Response:                              â•‘
â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â•‘  â”‚ ğŸ“¤ Send to Claude for response         â”‚
â•‘  â”‚ ğŸ“Š Analyze mood from this entry        â”‚
â•‘  â”‚ ğŸ’¾ Save as-is                         â”‚
â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â•‘                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

#### Accessibility Overlay (with VoiceOver active)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  BrainDump - VoiceOver Enabled             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                            â•‘
â•‘  SCREEN READER OUTPUT:                     â•‘
â•‘  "Record button, double tap to record      â•‘
â•‘   a new journal entry. Status: ready to    â•‘
â•‘   record. Voice input mode: enabled."      â•‘
â•‘                                            â•‘
â•‘  VOICE CONTROL COMPATIBLE:                 â•‘
â•‘  âœ“ Say "Record" â†’ starts recording        â•‘
â•‘  âœ“ Say "Stop" â†’ stops recording           â•‘
â•‘  âœ“ Say "Send" â†’ sends to AI               â•‘
â•‘  âœ“ Says "Delete" â†’ deletes entry          â•‘
â•‘                                            â•‘
â•‘  TAB NAVIGATION:                           â•‘
â•‘  [Record] â†’ [AI Provider] â†’ [Send] â†’ etc  â•‘
â•‘                                            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### 6.3 Error Scenarios & Recovery

#### Scenario 1: Microphone Too Far

```
DETECTION: Background noise > speech level

UI RESPONSE:
â”Œâ”€ Microphone Adjustment Needed â”€â”€â”€â”€â”€â”€â”
â”‚                                     â”‚
â”‚ âœ“ Voice level: Too quiet            â”‚
â”‚ âš  Background noise: Too loud        â”‚
â”‚                                     â”‚
â”‚ SUGGESTION:                         â”‚
â”‚ "Move phone closer to your mouth,   â”‚
â”‚  about 6 inches away."              â”‚
â”‚                                     â”‚
â”‚ ğŸ¤ [Visual distance indicator]      â”‚
â”‚    [Too close] â†â—â†’ [Too far]        â”‚
â”‚                                     â”‚
â”‚ [OK, I'm adjusting] [Retry Now]     â”‚
â”‚                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Scenario 2: Low Transcription Confidence

```
DETECTION: Confidence score 0.68 (low)

UI RESPONSE:
â”Œâ”€ Please Review Transcription â”€â”€â”€â”€â”€â”€â”
â”‚                                    â”‚
â”‚ I hard a relly gray day today.     â”‚
â”‚ The project demo when...           â”‚
â”‚                                    â”‚
â”‚ âš  Low confidence detected.         â”‚
â”‚ Would you like to:                 â”‚
â”‚                                    â”‚
â”‚ [Replay & Retry] [Accept & Edit]   â”‚
â”‚                                    â”‚
â”‚ (Replay shows waveform + transcript
â”‚  with low-confidence words marked) â”‚
â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Scenario 3: Network Error During AI Response

```
DETECTION: API request times out or fails

UI RESPONSE:
â”Œâ”€ Couldn't send to AI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                    â”‚
â”‚ Your transcript was saved locally: â”‚
â”‚ "I had a great day today..."       â”‚
â”‚                                    â”‚
â”‚ The AI response failed because:    â”‚
â”‚ â€¢ No internet connection, or       â”‚
â”‚ â€¢ API temporarily unavailable      â”‚
â”‚                                    â”‚
â”‚ [Save & Retry Later]               â”‚
â”‚ [Use Offline Response]             â”‚
â”‚                                    â”‚
â”‚ Recovery: Auto-retry on network    â”‚
â”‚ restoration (show in notifications)â”‚
â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Section 7: Implementation Checklist

### Phase 1: Core Voice UX (MVP)

- [ ] VAD implementation with 300-500ms tail silence detection
- [ ] Real-time waveform visualization during recording
- [ ] Peak level + background noise display
- [ ] Audio feedback system (beeps for start/stop/error)
- [ ] Implicit confidence confirmation (show transcript, allow edits)
- [ ] Edit-in-place transcript editing
- [ ] Error recovery for low-confidence transcripts (ask to retry)

### Phase 2: Accessibility (Priority High)

- [ ] WCAG 2.1 AA compliance audit
- [ ] VoiceOver testing on actual device
- [ ] Voice control testing (Ctrl+N keyboard equivalent)
- [ ] Audio ducking implementation
- [ ] Keyboard-only navigation path
- [ ] Screen reader labels match visible text
- [ ] High contrast mode support

### Phase 3: Mobile Polish

- [ ] Lock screen recording indicator
- [ ] Background audio mode (iOS)
- [ ] Haptic feedback tier system (post-recording)
- [ ] Audio ducking when other apps play
- [ ] Network state monitoring (auto-retry on reconnect)
- [ ] Recording timeout after 10 minutes (battery, safety)

### Phase 4: Advanced Features

- [ ] Speaker diarization (multi-person conversations)
- [ ] Confidence-based auto-save threshold tuning
- [ ] Voice commands for app navigation
- [ ] Custom wake word recognition
- [ ] Sentiment analysis from voice prosody (future)

---

## Section 8: Key Takeaways for Clear-Voice-App

1. **Confidence Scores Are Lies**: Don't show word-level confidence. Instead, show binary status (OK / Needs Review).

2. **Feedback is Multiplicative**: Visual + Audio + Haptic (when possible) feedback > any single modality. Users notice feedback 67% more when multi-sensory.

3. **Error Recovery Beats Error Prevention**: Users forgive occasional mishaps if recovery is clear and quick. Spend more time on recovery UX than prevention.

4. **Accessibility Isn't an Afterthought**: Voice + Screen Reader must coexist. Test with VoiceOver/TalkBack early and often.

5. **Implicit is Better Than Explicit** (when safe): Show transcripts without asking "Is this correct?" Force users to only confirm on critical actions (delete, send).

6. **VAD + Manual Override is Best**: Default to VAD for natural feel, but always provide manual stop button for user control.

7. **Audio Ducking is Essential on Mobile**: Users expect other audio to quiet when they're speaking. Implement from day 1.

8. **Test in Real Environments**: Lab-perfect UI fails in noisy cafes, cars, and parks. Test with background traffic, music, other speakers.

---

## Appendix A: WCAG 2.1 Success Criteria for Voice

| Criteria | Level | Application to BrainDump |
|----------|-------|------------------------|
| 2.1.4: Character Key Shortcuts | A | Don't use single-char shortcuts; test with voice control |
| 2.5.3: Label in Name | A | Button text must match programmatic name |
| 2.4.3: Focus Order | A | Tab navigation must be logical |
| 2.4.7: Focus Visible | AA | Show clear focus indicator on all buttons |
| 2.5.1: Pointer Gestures | A | Every gesture must have keyboard equivalent |
| 1.4.3: Contrast (Minimum) | AA | 4.5:1 for text, 3:1 for UI components |
| 1.4.11: Non-text Contrast | AA | Status indicators must use shape + color + text |

---

## Appendix B: Voice App Usability Study Findings

### What Works Well
- âœ“ Dictation of long text (voice > keyboard for >100 words)
- âœ“ Simple, single-intent commands ("What's the weather?")
- âœ“ Hands-free operation (driving, cooking, exercise)
- âœ“ Natural language journal entries (no structure required)

### What's Problematic
- âœ— Complex multi-step workflows (use GUI instead)
- âœ— Unique terminology (proprietary jargon, names)
- âœ— Real-time conversation (latency > 500ms feels sluggish)
- âœ— Voice-only error messages (must also show visually)

### Critical UX Metrics
- **Confidence Threshold**: 85%+ acceptable without review
- **Latency Target**: <500ms response time
- **Error Rate Acceptable**: <5% mishearing rate on common words
- **User Satisfaction**: 4+/5 stars when error recovery is clear

---

## References & Further Reading

- Google Design: "Speaking the Same Language: VUI Design" - https://design.google/library/speaking-the-same-language-vui
- NN/g: "Voice Interaction UX" - https://www.nngroup.com/articles/voice-interaction-ux/
- WCAG 2.1 Voice Input Guidelines - https://www.w3.org/WAI/standards-guidelines/wcag/
- AssemblyAI: Real-time Speech-to-Text Guide - https://www.assemblyai.com/blog/real-time-speech-to-text/
- Picovoice: Speaker Diarization in Production - https://picovoice.ai/blog/speaker-diarization/
- Apple HIG: Accessibility - https://developer.apple.com/design/human-interface-guidelines/accessibility/
- Android Accessibility: Voice Control - https://support.google.com/accessibility/android/

---

**Report Status**: Complete
**Last Updated**: 2025-11-16
**Next Steps**: Implement Phase 1 (Core Voice UX) during Sprint 1
